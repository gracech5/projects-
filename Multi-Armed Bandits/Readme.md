## Multi-Armed Bandits

This Jupyter Notebook contains Python code that tests out various multi-armed bandit algorithms such as Epsilon-Greedy, Adaptive Epsilon-Greedy and UCB1. 
The algorithms are tested on an ads dataset as well as a simple two-armed bandit with a win-rate of 0.25 and 0.5.    

The code was adapted from the following sources below: 

Sources:
https://blog.devgenius.io/how-to-solve-the-multi-armed-bandit-problem-epsilon-greedy-approach-ebe286390578 
